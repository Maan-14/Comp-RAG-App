{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **RAG APPLICATION FOR TEAMSOLVE**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import chromadb\n",
    "from pypdf import PdfReader\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter, SentenceTransformersTokenTextSplitter\n",
    "from chromadb.utils.embedding_functions import SentenceTransformerEmbeddingFunction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title:  MeshAnything: Artist -Created Mesh Generation with Autoregressive Transformers  \n",
      "Authors:  buaacyw/meshanything  \n",
      "Date:  14 Jun 2024  \n",
      "Description:  Recently, 3D assets created via reconstruction and generation have matched the \n",
      "quality of manually crafted assets, highlighting their potential for replacement.  \n",
      "Stats:  417, 5.09 stars / hour  \n",
      "Categories:  Decoder  \n",
      "Links:  Paper, Code  \n",
      " \n",
      "Title:  Accessing GPT -4 level Mathematical Olympiad Solutions via Monte Carlo Tree Self -\n",
      "refine with LLaMa -3 8B  \n",
      "Authors:  trotsky1997/mathblackbox  \n",
      "Date:  11 Jun 2024  \n",
      "Description:  This paper introduces the MCT Self -Refine algorithm, an innovative integration of \n",
      "Large Language Models (LLMs) with Monte Carlo Tree Search (MCTS), designed to enhance \n",
      "performance in complex mathematical reasoning tasks.  \n",
      "Stats:  279, 2.35 stars / hour  \n",
      "Categories:  Decision Making, GSM8K +2  \n",
      "Links:  Paper, Code  \n",
      " \n",
      "Title:  TextGrad: Automatic 'Differentiation' via Text  \n",
      "Authors:  zou-group/textgrad  \n",
      "Date:  11 Jun 2024  \n",
      "Description:  Without modifying the framework, TextGrad improves the zero -shot accuracy of \n",
      "GPT -4o in Google -Proof Question Answering, yields significant relative performance gain in \n",
      "optimizing LeetCode -Hard coding problem solutions, improves prompts for reasoning, desi gns \n",
      "new druglike small molecules with desirable in silico binding, and designs radiation oncology \n",
      "treatment plans with high specificity.  \n",
      "Stats:  485, 2.04 stars / hour  \n",
      "Categories:  Question Answering, Specificity  \n",
      "Links:  Paper, Code  \n",
      " \n",
      "Title:  Scalable MatMul -free Language Modeling  \n",
      "Authors:  ridgerchu/matmulfreellm  \n",
      "Date:  4 Jun 2024  \n",
      "Description:  Our experiments show that our proposed MatMul -free models achieve performance \n",
      "on-par with state -of-the-art Transformers that require far more memory during inference at a \n",
      "scale up to at least 2.7B parameters.  \n",
      "Stats:  2,140, 1.98 stars / hour\n"
     ]
    }
   ],
   "source": [
    "reader = PdfReader(\"documents/RAG Input Doc.pdf\")\n",
    "pdf_texts = [p.extract_text().strip() for p in reader.pages]\n",
    "\n",
    "# Filter the empty strings\n",
    "pdf_texts = [text for text in pdf_texts if text]\n",
    "\n",
    "print(pdf_texts[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### The reason of first doing character split and then doing SentenceTransformersTokenTextSplitter is that ```Large documents may not fit entirely into memory. By first breaking the text into character-level chunks, you can process smaller portions at a time, reducing the memory requirements for each step.```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Total chunks: 5\n"
     ]
    }
   ],
   "source": [
    "character_splitter = RecursiveCharacterTextSplitter(\n",
    "    # It will split on the basis of these below characters like newline etc\n",
    "    separators=[\"\\n\\n\", \"\\n\", \". \", \" \", \"\"],\n",
    "    # If after splitting at separators, it got a big length then it will break down into chunk size of 1000 characters maximum\n",
    "    chunk_size=550,\n",
    "    chunk_overlap=0\n",
    ")\n",
    "character_split_texts = character_splitter.split_text('\\n\\n'.join(pdf_texts))\n",
    "\n",
    "print(f\"\\nTotal chunks: {len(character_split_texts)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### ```Character Splitter is not enough due the reason that the embedder which we have to use has limited 256 characters or tokens context window```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Total chunks: 5\n"
     ]
    }
   ],
   "source": [
    "token_splitter = SentenceTransformersTokenTextSplitter(chunk_overlap=0, tokens_per_chunk=256) \n",
    "\n",
    "token_split_texts = []\n",
    "for text in character_split_texts:\n",
    "    token_split_texts += token_splitter.split_text(text)\n",
    "\n",
    "print(f\"\\nTotal chunks: {len(token_split_texts)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_function = SentenceTransformerEmbeddingFunction()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chroma_client = chromadb.Client()\n",
    "chroma_collection = chroma_client.create_collection(\"rag_app1\", embedding_function=embedding_function)\n",
    "\n",
    "ids = [str(i) for i in range(len(token_split_texts))]\n",
    "\n",
    "chroma_collection.add(ids=ids, documents=token_split_texts)\n",
    "chroma_collection.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "title : meshanything : artist - created mesh generation with autoregressive transformers authors : buaacyw / meshanything date : 14 jun 2024 description : recently, 3d assets created via reconstruction and generation have matched the quality of manually crafted assets, highlighting their potential for replacement. stats : 417, 5. 09 stars / hour categories : decoder links : paper, code title : accessing gpt - 4 level mathematical olympiad solutions via monte carlo tree self - refine with llama - 3 8b\n",
      "\n",
      "\n",
      "categories : language modelling links : paper, code title : videollama 2 : advancing spatial - temporal modeling and audio understanding in video - llms authors : damo - nlp - sg / videollama2 date : 11 jun 2024 description : in this paper, we present the videollama 2, a set of video large language models ( video - llms ) designed to enhance spatial - temporal modeling and audio understanding in video and audio - oriented tasks. stats : 318, 1. 50 stars / hour categories : multiple - choice, question answering + 3 links : paper, code\n",
      "\n",
      "\n",
      "authors : trotsky1997 / mathblackbox date : 11 jun 2024 description : this paper introduces the mct self - refine algorithm, an innovative integration of large language models ( llms ) with monte carlo tree search ( mcts ), designed to enhance performance in complex mathematical reasoning tasks. stats : 279, 2. 35 stars / hour categories : decision making, gsm8k + 2 links : paper, code title : textgrad : automatic'differentiation'via text authors : zou - group / textgrad date : 11 jun 2024\n",
      "\n",
      "\n",
      "title : scalable matmul - free language modeling authors : ridgerchu / matmulfreellm date : 4 jun 2024 description : our experiments show that our proposed matmul - free models achieve performance on - par with state - of - the - art transformers that require far more memory during inference at a scale up to at least 2. 7b parameters. stats : 2, 140, 1. 98 stars / hour\n",
      "\n",
      "\n",
      "description : without modifying the framework, textgrad improves the zero - shot accuracy of gpt - 4o in google - proof question answering, yields significant relative performance gain in optimizing leetcode - hard coding problem solutions, improves prompts for reasoning, desi gns new druglike small molecules with desirable in silico binding, and designs radiation oncology treatment plans with high specificity. stats : 485, 2. 04 stars / hour categories : question answering, specificity links : paper, code\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "query = \"Which paper received the highest number of stars per hour?\"\n",
    "\n",
    "# Here chroma automatically embeds using the embedding function we have used above the query and give retrieved documents\n",
    "results = chroma_collection.query(query_texts=[query], n_results=5)\n",
    "retrieved_documents = results['documents'][0]\n",
    "\n",
    "for document in retrieved_documents:\n",
    "    print(document)\n",
    "    print('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "import replicate\n",
    "\n",
    "replicate = replicate.Client(api_token='r8_RL3XYRWMZBrlqnnn3xPynfEH4Mc40ej1RYY8S')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rag(query, retrieved_documents):\n",
    "    information = \"\\n\\n\".join(retrieved_documents)\n",
    "\n",
    "    output = replicate.run(\n",
    "        \"meta/llama-2-70b-chat:02e509c789964a7ea8736978a43525956ef40397be9033abf9fd2badfe68c9e3\",\n",
    "        input={\n",
    "            \"prompt\":f\"You are a helpful expert research assistant. Your users are asking questions about information contained in reports or files.\"\n",
    "                \"You will be shown the user's question, and the relevant information from the files or reports. Answer the user's question using only this information.\" \n",
    "                f\"Question: {query}. \\n Information: {information}\",\n",
    "            }\n",
    "    )\n",
    "\n",
    "    ans = []\n",
    "    for item in output:\n",
    "        ans.append(item)\n",
    "\n",
    "    str1 = ''.join(str(e) for e in ans)\n",
    "    return str1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " The paper that received the highest number of stars per hour is \"Textgrad : Automatic Differentiation via Text\" by Zou-Group/Textgrad, with 485 stars and a rate of 2.04 stars per hour.\n"
     ]
    }
   ],
   "source": [
    "output = rag(query=query, retrieved_documents=retrieved_documents)\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "title : meshanything : artist - created mesh generation with autoregressive transformers authors : buaacyw / meshanything date : 14 jun 2024 description : recently, 3d assets created via reconstruction and generation have matched the quality of manually crafted assets, highlighting their potential for replacement. stats : 417, 5. 09 stars / hour categories : decoder links : paper, code title : accessing gpt - 4 level mathematical olympiad solutions via monte carlo tree self - refine with llama - 3 8b\n",
      "\n",
      "\n",
      "categories : language modelling links : paper, code title : videollama 2 : advancing spatial - temporal modeling and audio understanding in video - llms authors : damo - nlp - sg / videollama2 date : 11 jun 2024 description : in this paper, we present the videollama 2, a set of video large language models ( video - llms ) designed to enhance spatial - temporal modeling and audio understanding in video and audio - oriented tasks. stats : 318, 1. 50 stars / hour categories : multiple - choice, question answering + 3 links : paper, code\n",
      "\n",
      "\n",
      "title : scalable matmul - free language modeling authors : ridgerchu / matmulfreellm date : 4 jun 2024 description : our experiments show that our proposed matmul - free models achieve performance on - par with state - of - the - art transformers that require far more memory during inference at a scale up to at least 2. 7b parameters. stats : 2, 140, 1. 98 stars / hour\n",
      "\n",
      "\n",
      "description : without modifying the framework, textgrad improves the zero - shot accuracy of gpt - 4o in google - proof question answering, yields significant relative performance gain in optimizing leetcode - hard coding problem solutions, improves prompts for reasoning, desi gns new druglike small molecules with desirable in silico binding, and designs radiation oncology treatment plans with high specificity. stats : 485, 2. 04 stars / hour categories : question answering, specificity links : paper, code\n",
      "\n",
      "\n",
      "authors : trotsky1997 / mathblackbox date : 11 jun 2024 description : this paper introduces the mct self - refine algorithm, an innovative integration of large language models ( llms ) with monte carlo tree search ( mcts ), designed to enhance performance in complex mathematical reasoning tasks. stats : 279, 2. 35 stars / hour categories : decision making, gsm8k + 2 links : paper, code title : textgrad : automatic'differentiation'via text authors : zou - group / textgrad date : 11 jun 2024\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "query = \"What is the focus of the 'MeshAnything' project?\"\n",
    "\n",
    "results = chroma_collection.query(query_texts=[query], n_results=5)\n",
    "retrieved_documents = results['documents'][0]\n",
    "\n",
    "for document in retrieved_documents:\n",
    "    print(document)\n",
    "    print('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Based on the information provided, the focus of the 'MeshAnything' project appears to be on creating 3D assets using autoregressive transformers, with the goal of matching the quality of manually crafted assets. The project's description highlights the potential for replacement of manual asset creation with AI-generated assets.\n"
     ]
    }
   ],
   "source": [
    "output = rag(query=query, retrieved_documents=retrieved_documents)\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "authors : trotsky1997 / mathblackbox date : 11 jun 2024 description : this paper introduces the mct self - refine algorithm, an innovative integration of large language models ( llms ) with monte carlo tree search ( mcts ), designed to enhance performance in complex mathematical reasoning tasks. stats : 279, 2. 35 stars / hour categories : decision making, gsm8k + 2 links : paper, code title : textgrad : automatic'differentiation'via text authors : zou - group / textgrad date : 11 jun 2024\n",
      "\n",
      "\n",
      "title : scalable matmul - free language modeling authors : ridgerchu / matmulfreellm date : 4 jun 2024 description : our experiments show that our proposed matmul - free models achieve performance on - par with state - of - the - art transformers that require far more memory during inference at a scale up to at least 2. 7b parameters. stats : 2, 140, 1. 98 stars / hour\n",
      "\n",
      "\n",
      "categories : language modelling links : paper, code title : videollama 2 : advancing spatial - temporal modeling and audio understanding in video - llms authors : damo - nlp - sg / videollama2 date : 11 jun 2024 description : in this paper, we present the videollama 2, a set of video large language models ( video - llms ) designed to enhance spatial - temporal modeling and audio understanding in video and audio - oriented tasks. stats : 318, 1. 50 stars / hour categories : multiple - choice, question answering + 3 links : paper, code\n",
      "\n",
      "\n",
      "description : without modifying the framework, textgrad improves the zero - shot accuracy of gpt - 4o in google - proof question answering, yields significant relative performance gain in optimizing leetcode - hard coding problem solutions, improves prompts for reasoning, desi gns new druglike small molecules with desirable in silico binding, and designs radiation oncology treatment plans with high specificity. stats : 485, 2. 04 stars / hour categories : question answering, specificity links : paper, code\n",
      "\n",
      "\n",
      "title : meshanything : artist - created mesh generation with autoregressive transformers authors : buaacyw / meshanything date : 14 jun 2024 description : recently, 3d assets created via reconstruction and generation have matched the quality of manually crafted assets, highlighting their potential for replacement. stats : 417, 5. 09 stars / hour categories : decoder links : paper, code title : accessing gpt - 4 level mathematical olympiad solutions via monte carlo tree self - refine with llama - 3 8b\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "query = \"Which paper discusses the integration of Large Language Models with Monte Carlo Tree Search?\"\n",
    "\n",
    "results = chroma_collection.query(query_texts=[query], n_results=5)\n",
    "retrieved_documents = results['documents'][0]\n",
    "\n",
    "for document in retrieved_documents:\n",
    "    print(document)\n",
    "    print('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " The paper that discusses the integration of Large Language Models with Monte Carlo Tree Search is \"Textgrad: Automatic Differentiation via Text\" by Trotsky1997/MathBlackbox, dated June 11, 2024. The paper introduces the mct-self-refine algorithm, which integrates Large Language Models (LLMs) with Monte Carlo Tree Search (MCTS) to enhance performance in complex mathematical reasoning tasks.\n"
     ]
    }
   ],
   "source": [
    "output = rag(query=query, retrieved_documents=retrieved_documents)\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "categories : language modelling links : paper, code title : videollama 2 : advancing spatial - temporal modeling and audio understanding in video - llms authors : damo - nlp - sg / videollama2 date : 11 jun 2024 description : in this paper, we present the videollama 2, a set of video large language models ( video - llms ) designed to enhance spatial - temporal modeling and audio understanding in video and audio - oriented tasks. stats : 318, 1. 50 stars / hour categories : multiple - choice, question answering + 3 links : paper, code\n",
      "\n",
      "\n",
      "title : meshanything : artist - created mesh generation with autoregressive transformers authors : buaacyw / meshanything date : 14 jun 2024 description : recently, 3d assets created via reconstruction and generation have matched the quality of manually crafted assets, highlighting their potential for replacement. stats : 417, 5. 09 stars / hour categories : decoder links : paper, code title : accessing gpt - 4 level mathematical olympiad solutions via monte carlo tree self - refine with llama - 3 8b\n",
      "\n",
      "\n",
      "description : without modifying the framework, textgrad improves the zero - shot accuracy of gpt - 4o in google - proof question answering, yields significant relative performance gain in optimizing leetcode - hard coding problem solutions, improves prompts for reasoning, desi gns new druglike small molecules with desirable in silico binding, and designs radiation oncology treatment plans with high specificity. stats : 485, 2. 04 stars / hour categories : question answering, specificity links : paper, code\n",
      "\n",
      "\n",
      "title : scalable matmul - free language modeling authors : ridgerchu / matmulfreellm date : 4 jun 2024 description : our experiments show that our proposed matmul - free models achieve performance on - par with state - of - the - art transformers that require far more memory during inference at a scale up to at least 2. 7b parameters. stats : 2, 140, 1. 98 stars / hour\n",
      "\n",
      "\n",
      "authors : trotsky1997 / mathblackbox date : 11 jun 2024 description : this paper introduces the mct self - refine algorithm, an innovative integration of large language models ( llms ) with monte carlo tree search ( mcts ), designed to enhance performance in complex mathematical reasoning tasks. stats : 279, 2. 35 stars / hour categories : decision making, gsm8k + 2 links : paper, code title : textgrad : automatic'differentiation'via text authors : zou - group / textgrad date : 11 jun 2024\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "query = \"What advancements does the 'VideoLLaMA 2' paper propose?\"\n",
    "\n",
    "results = chroma_collection.query(query_texts=[query], n_results=5)\n",
    "retrieved_documents = results['documents'][0]\n",
    "\n",
    "for document in retrieved_documents:\n",
    "    print(document)\n",
    "    print('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " The 'VideoLLaMA 2' paper proposes several advancements in spatial-temporal modeling and audio understanding for video language models (ViLlMs). The proposed model, VideoLLaMA 2, is designed to enhance performance in video and audio-oriented tasks, including question answering, multiple-choice, and decision-making.\n",
      "\n",
      "The paper introduces several novel techniques, including:\n",
      "\n",
      "1. Spatial-Temporal Modeling: VideoLLaMA 2 incorporates a spatial-temporal graph convolutional network (ST-GCN)\n"
     ]
    }
   ],
   "source": [
    "output = rag(query=query, retrieved_documents=retrieved_documents)\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "authors : trotsky1997 / mathblackbox date : 11 jun 2024 description : this paper introduces the mct self - refine algorithm, an innovative integration of large language models ( llms ) with monte carlo tree search ( mcts ), designed to enhance performance in complex mathematical reasoning tasks. stats : 279, 2. 35 stars / hour categories : decision making, gsm8k + 2 links : paper, code title : textgrad : automatic'differentiation'via text authors : zou - group / textgrad date : 11 jun 2024\n",
      "\n",
      "\n",
      "title : meshanything : artist - created mesh generation with autoregressive transformers authors : buaacyw / meshanything date : 14 jun 2024 description : recently, 3d assets created via reconstruction and generation have matched the quality of manually crafted assets, highlighting their potential for replacement. stats : 417, 5. 09 stars / hour categories : decoder links : paper, code title : accessing gpt - 4 level mathematical olympiad solutions via monte carlo tree self - refine with llama - 3 8b\n",
      "\n",
      "\n",
      "description : without modifying the framework, textgrad improves the zero - shot accuracy of gpt - 4o in google - proof question answering, yields significant relative performance gain in optimizing leetcode - hard coding problem solutions, improves prompts for reasoning, desi gns new druglike small molecules with desirable in silico binding, and designs radiation oncology treatment plans with high specificity. stats : 485, 2. 04 stars / hour categories : question answering, specificity links : paper, code\n",
      "\n",
      "\n",
      "title : scalable matmul - free language modeling authors : ridgerchu / matmulfreellm date : 4 jun 2024 description : our experiments show that our proposed matmul - free models achieve performance on - par with state - of - the - art transformers that require far more memory during inference at a scale up to at least 2. 7b parameters. stats : 2, 140, 1. 98 stars / hour\n",
      "\n",
      "\n",
      "categories : language modelling links : paper, code title : videollama 2 : advancing spatial - temporal modeling and audio understanding in video - llms authors : damo - nlp - sg / videollama2 date : 11 jun 2024 description : in this paper, we present the videollama 2, a set of video large language models ( video - llms ) designed to enhance spatial - temporal modeling and audio understanding in video and audio - oriented tasks. stats : 318, 1. 50 stars / hour categories : multiple - choice, question answering + 3 links : paper, code\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "query = \"Which paper was published most recently?\"\n",
    "\n",
    "results = chroma_collection.query(query_texts=[query], n_results=5)\n",
    "retrieved_documents = results['documents'][0]\n",
    "\n",
    "for document in retrieved_documents:\n",
    "    print(document)\n",
    "    print('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " The paper that was published most recently is \"meshanything: artist-created mesh generation with autoregressive transformers\" by buaacyw/meshanything, which was published on June 14, 2024.\n"
     ]
    }
   ],
   "source": [
    "output = rag(query=query, retrieved_documents=retrieved_documents)\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "title : scalable matmul - free language modeling authors : ridgerchu / matmulfreellm date : 4 jun 2024 description : our experiments show that our proposed matmul - free models achieve performance on - par with state - of - the - art transformers that require far more memory during inference at a scale up to at least 2. 7b parameters. stats : 2, 140, 1. 98 stars / hour\n",
      "\n",
      "\n",
      "authors : trotsky1997 / mathblackbox date : 11 jun 2024 description : this paper introduces the mct self - refine algorithm, an innovative integration of large language models ( llms ) with monte carlo tree search ( mcts ), designed to enhance performance in complex mathematical reasoning tasks. stats : 279, 2. 35 stars / hour categories : decision making, gsm8k + 2 links : paper, code title : textgrad : automatic'differentiation'via text authors : zou - group / textgrad date : 11 jun 2024\n",
      "\n",
      "\n",
      "categories : language modelling links : paper, code title : videollama 2 : advancing spatial - temporal modeling and audio understanding in video - llms authors : damo - nlp - sg / videollama2 date : 11 jun 2024 description : in this paper, we present the videollama 2, a set of video large language models ( video - llms ) designed to enhance spatial - temporal modeling and audio understanding in video and audio - oriented tasks. stats : 318, 1. 50 stars / hour categories : multiple - choice, question answering + 3 links : paper, code\n",
      "\n",
      "\n",
      "title : meshanything : artist - created mesh generation with autoregressive transformers authors : buaacyw / meshanything date : 14 jun 2024 description : recently, 3d assets created via reconstruction and generation have matched the quality of manually crafted assets, highlighting their potential for replacement. stats : 417, 5. 09 stars / hour categories : decoder links : paper, code title : accessing gpt - 4 level mathematical olympiad solutions via monte carlo tree self - refine with llama - 3 8b\n",
      "\n",
      "\n",
      "description : without modifying the framework, textgrad improves the zero - shot accuracy of gpt - 4o in google - proof question answering, yields significant relative performance gain in optimizing leetcode - hard coding problem solutions, improves prompts for reasoning, desi gns new druglike small molecules with desirable in silico binding, and designs radiation oncology treatment plans with high specificity. stats : 485, 2. 04 stars / hour categories : question answering, specificity links : paper, code\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "query = \"Identify a paper that deals with language modeling and its scalability.\"\n",
    "\n",
    "results = chroma_collection.query(query_texts=[query], n_results=5)\n",
    "retrieved_documents = results['documents'][0]\n",
    "\n",
    "for document in retrieved_documents:\n",
    "    print(document)\n",
    "    print('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " The paper that deals with language modeling and its scalability is \"Scalable MatMul-Free Language Modeling\" by Ridgerchu and MatMulFreeLLM. The paper was published on June 4, 2024, and the authors propose a matmul-free language model that achieves performance on par with state-of-the-art transformers while requiring less memory during inference. The paper also presents experiments that show the scalability of the proposed model up to 2.7 billion parameters.\n"
     ]
    }
   ],
   "source": [
    "output = rag(query=query, retrieved_documents=retrieved_documents)\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "description : without modifying the framework, textgrad improves the zero - shot accuracy of gpt - 4o in google - proof question answering, yields significant relative performance gain in optimizing leetcode - hard coding problem solutions, improves prompts for reasoning, desi gns new druglike small molecules with desirable in silico binding, and designs radiation oncology treatment plans with high specificity. stats : 485, 2. 04 stars / hour categories : question answering, specificity links : paper, code\n",
      "\n",
      "\n",
      "authors : trotsky1997 / mathblackbox date : 11 jun 2024 description : this paper introduces the mct self - refine algorithm, an innovative integration of large language models ( llms ) with monte carlo tree search ( mcts ), designed to enhance performance in complex mathematical reasoning tasks. stats : 279, 2. 35 stars / hour categories : decision making, gsm8k + 2 links : paper, code title : textgrad : automatic'differentiation'via text authors : zou - group / textgrad date : 11 jun 2024\n",
      "\n",
      "\n",
      "categories : language modelling links : paper, code title : videollama 2 : advancing spatial - temporal modeling and audio understanding in video - llms authors : damo - nlp - sg / videollama2 date : 11 jun 2024 description : in this paper, we present the videollama 2, a set of video large language models ( video - llms ) designed to enhance spatial - temporal modeling and audio understanding in video and audio - oriented tasks. stats : 318, 1. 50 stars / hour categories : multiple - choice, question answering + 3 links : paper, code\n",
      "\n",
      "\n",
      "title : scalable matmul - free language modeling authors : ridgerchu / matmulfreellm date : 4 jun 2024 description : our experiments show that our proposed matmul - free models achieve performance on - par with state - of - the - art transformers that require far more memory during inference at a scale up to at least 2. 7b parameters. stats : 2, 140, 1. 98 stars / hour\n",
      "\n",
      "\n",
      "title : meshanything : artist - created mesh generation with autoregressive transformers authors : buaacyw / meshanything date : 14 jun 2024 description : recently, 3d assets created via reconstruction and generation have matched the quality of manually crafted assets, highlighting their potential for replacement. stats : 417, 5. 09 stars / hour categories : decoder links : paper, code title : accessing gpt - 4 level mathematical olympiad solutions via monte carlo tree self - refine with llama - 3 8b\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "query = \"Which paper aims at improving accuracy in Google-Proof Question Answering?\"\n",
    "\n",
    "results = chroma_collection.query(query_texts=[query], n_results=5)\n",
    "retrieved_documents = results['documents'][0]\n",
    "\n",
    "for document in retrieved_documents:\n",
    "    print(document)\n",
    "    print('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " The paper that aims at improving accuracy in Google-Proof Question Answering is \"Textgrad: Automatic Differentiation'via Text\" by Trotsky1997/MathBlackBox. This paper introduces a new algorithm called MCT Self-Refine, which integrates Large Language Models (LLMs) with Monte Carlo Tree Search (MCTS) to enhance performance in complex mathematical reasoning tasks. The authors claim that their approach yields significant relative performance gain in optimizing LeetCode-hard coding problem solutions and improves prompts for reasoning. They also demonstrate the effect\n"
     ]
    }
   ],
   "source": [
    "output = rag(query=query, retrieved_documents=retrieved_documents)\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "authors : trotsky1997 / mathblackbox date : 11 jun 2024 description : this paper introduces the mct self - refine algorithm, an innovative integration of large language models ( llms ) with monte carlo tree search ( mcts ), designed to enhance performance in complex mathematical reasoning tasks. stats : 279, 2. 35 stars / hour categories : decision making, gsm8k + 2 links : paper, code title : textgrad : automatic'differentiation'via text authors : zou - group / textgrad date : 11 jun 2024\n",
      "\n",
      "\n",
      "description : without modifying the framework, textgrad improves the zero - shot accuracy of gpt - 4o in google - proof question answering, yields significant relative performance gain in optimizing leetcode - hard coding problem solutions, improves prompts for reasoning, desi gns new druglike small molecules with desirable in silico binding, and designs radiation oncology treatment plans with high specificity. stats : 485, 2. 04 stars / hour categories : question answering, specificity links : paper, code\n",
      "\n",
      "\n",
      "categories : language modelling links : paper, code title : videollama 2 : advancing spatial - temporal modeling and audio understanding in video - llms authors : damo - nlp - sg / videollama2 date : 11 jun 2024 description : in this paper, we present the videollama 2, a set of video large language models ( video - llms ) designed to enhance spatial - temporal modeling and audio understanding in video and audio - oriented tasks. stats : 318, 1. 50 stars / hour categories : multiple - choice, question answering + 3 links : paper, code\n",
      "\n",
      "\n",
      "title : scalable matmul - free language modeling authors : ridgerchu / matmulfreellm date : 4 jun 2024 description : our experiments show that our proposed matmul - free models achieve performance on - par with state - of - the - art transformers that require far more memory during inference at a scale up to at least 2. 7b parameters. stats : 2, 140, 1. 98 stars / hour\n",
      "\n",
      "\n",
      "title : meshanything : artist - created mesh generation with autoregressive transformers authors : buaacyw / meshanything date : 14 jun 2024 description : recently, 3d assets created via reconstruction and generation have matched the quality of manually crafted assets, highlighting their potential for replacement. stats : 417, 5. 09 stars / hour categories : decoder links : paper, code title : accessing gpt - 4 level mathematical olympiad solutions via monte carlo tree self - refine with llama - 3 8b\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "query = \"List the categories covered by the paper titled 'TextGrad: Automatic 'Differentiation' via Text'.\"\n",
    "\n",
    "results = chroma_collection.query(query_texts=[query], n_results=5)\n",
    "retrieved_documents = results['documents'][0]\n",
    "\n",
    "for document in retrieved_documents:\n",
    "    print(document)\n",
    "    print('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Sure, I'd be happy to help! The paper titled \"TextGrad: Automatic 'Differentiation' via Text\" covers the following categories:\n",
      "\n",
      "* Decision making\n",
      "* GSM8K (a dataset of mathematical problems)\n",
      "* Question answering\n",
      "* Specificity\n",
      "* Language modeling\n",
      "\n",
      "The authors propose a method called TextGrad, which uses a combination of large language models and Monte Carlo Tree Search to enhance performance in complex mathematical reasoning tasks. They evaluate the effectiveness of TextGrad on several benchmarks, including Google Proof Question Answering and LeetCode-hard coding problem solutions\n"
     ]
    }
   ],
   "source": [
    "output = rag(query=query, retrieved_documents=retrieved_documents)\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Additional Q/A from a PDF Research Paper**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "979-8-3503-9478-8/24/$31.00 ©2024 IEEE Machine Learning and Mediapipe Assisted Sign \n",
      "Gesture-based Smart Keyboard for Deaf and Blind \n",
      "People \n",
      "Arsalan Ali  \n",
      "Department of Biomedical Engineering  \n",
      "University of Engineering and \n",
      "Technology, \n",
      "Lahore, 54890, Pakistan \n",
      "2019bme111@uet.edu.pk Muhammad Hamza Zulfiqar  \n",
      "Department of Biomedical Engineering  \n",
      "University of Engineering and \n",
      "Technology, \n",
      "Lahore, 54890, Pakistan  \n",
      "hamzazulfiqar@uet.edu.pkMuhammad Qasim Mehmood \n",
      "Micro Nano Lab, Electrical \n",
      "Engineering Department, Information \n",
      "Technology University (ITU) of the \n",
      "Punjab, Ferozepur Road, Lahore 54600, \n",
      "Pakistan  \n",
      "qasim.mehmood@itu.edu.pk \n",
      " \n",
      "Abstract — There are 1.1 billion deaf and 2.2 billion blind \n",
      "people, and many people have speech impairments. These \n",
      "disabilities cause them to be unable to communicate with others \n",
      "and use modern technologies. This paper presents a real-time \n",
      "smart touchless keypad by which people with blindness, \n",
      "deafness, and speech impairments can interact with the \n",
      "computer with the help of 37 hand gestures using a single \n",
      "camera. The presented solution uses a hand tracking module \n",
      "from the mediapipe library for feature extraction, a random \n",
      "forest algorithm for the classification of gestures, and a \n",
      "PyAutoGUI library for controlling the mouse and keyboard \n",
      "according to the classified hand gestures. The presented solution \n",
      "has achieved an accuracy of 99.66% on the test set, indicating \n",
      "that this system can also detect gestures for communication with \n",
      "deaf or speech-impaired people. Overall, this system employs \n",
      "computer vision and machine learning techniques to improve \n",
      "the lives of the deaf, blind, and mute people. \n",
      "Keywords—sign gesture, mediapipe, smart keyboard, deaf, \n",
      "blind, human-computer interaction \n",
      "I. INTRODUCTION  \n",
      "Communication is an effective tool to share ideas, thoughts, \n",
      "and feelings. Communication between humans makes life \n",
      "easier. But there is a gap because, unfortunately, there is a \n",
      "community of deaf and visually impaired people who cannot \n",
      "communicate with other people. According to the World \n",
      "Health Organization, 1.1 billion people are living with \n",
      "deafness, and 2.2 billion people are living with visual \n",
      "impairments [1], [2]. Many deaf people even cannot speak as \n",
      "well. Advancements in technology have made our lives \n",
      "easier. Still, technology has not proved so beneficial for deaf, \n",
      "mute, and visually impaired people because they are unable \n",
      "to communicate with other people and even cannot interact \n",
      "with modern technologies like computers  [3]. It is necessary \n",
      "to communicate with modern technology because technology \n",
      "is an integral part of society nowadays. Technology assists \n",
      "society in every area of life like. Google Maps helps millions \n",
      "of people in navigation. In the same way, a keypad is used to \n",
      "write messages for the purpose of communication. But to \n",
      "interact with technology, there is a need for communication \n",
      "between humans and machines like computers.  So, keeping \n",
      "this need for communication for deaf and visually impaired \n",
      "people, many sign languages have been introduced in the \n",
      "world by which deaf people can communicate with the other \n",
      "people and also with technology. Almost all the sign \n",
      "languages are in the form of gestures or visuals. These are \n",
      "different according to sociolinguistic demography [4].This \n",
      "solution needs an interpreter who understands the signs of \n",
      "that language. This is the costly solution for having interpreter and also makes deaf and visually impaired people \n",
      "dependent on others for communication. So there is need of \n",
      "technological solution which is cost effective and makes the \n",
      "effected people independent for interpersonal communication \n",
      "and communication with modern technology. \n",
      " Many solutions have been proposed, but there are \n",
      "three famous ones. The first solution is based on computer \n",
      "vision, the second is a sensor-based solution, and the third is \n",
      "voice assistant-based technology that only works for blind \n",
      "people, not for deaf people. The first solution processes \n",
      "images or videos to determine the relevant sign. Mobile \n",
      "cameras or other web-common cams can be used to take \n",
      "images. On the other hand, in the second solution, sensors are \n",
      "placed on the hand or fingers, and then the data from the \n",
      "sensors is analyzed to determine the relevant sign of the hand \n",
      "[5]. As the second solution is a sensor-based approach, also \n",
      "known as the data-glove approach, in which we mostly detect \n",
      "the hand position, angle of fingers bending, wrist movement \n",
      "etc.  [6]. The third solution is a voice assistant-based solution \n",
      "which helps blind people to communicate with technology \n",
      "like Apple Siri. \n",
      " J. Rekha used a multiclass nonlinear support vector \n",
      "machine to classify the signs of Indian Sign Language with a \n",
      "91.3% rate of recognition [7]. R. Sutjiadi presented the deep \n",
      "convolution neural network that can classify the 26 signs of \n",
      "Indonesian Sign Language with an accuracy of 75.38%[8]. \n",
      "Jyotishman Bora presented a framework that can classify \n",
      "only 9 static gestures of Assamese Sign Language using feed-\n",
      "forward neural network with an accuracy of 99%[9]. Yutong \n",
      "Gu presented a classification model that can classify the 26 \n",
      "dynamic signs of American Sign Language with an average \n",
      "accuracy of 74.8% [10]. A. M. Buttar used a hybrid approach \n",
      "with Mediapipe Holistic model and YoloV6 to classify signs \n",
      "with an accuracy of 92% and 96%, respectively [11]. \n",
      "Francisco Morillas-Espejo presented a solution named \n",
      "sign4all based on a deep convolution neural network in which \n",
      "they recognized the sign using the ResNet50 framework and \n",
      "got an accuracy of 79.96% on RGB images. They also \n",
      "designed virtual avatars to write letter by letter [12]. \n",
      " M. Rinalduzzi presented a magnetic positioning \n",
      "system-based solution where the wearable transmitting nodes \n",
      "are placed in a specific 3D space, and the receiving nodes, \n",
      "after receiving the message from the transmitting nodes, \n",
      "classify the 24 signs of Sign Language with an accuracy of \n",
      "97% [13]. K. Bhat presented a smart glove employing flex \n",
      "sensors to detect finger movement. The smart glove interprets \n",
      "the hand's signs using flex sensors and converts them into \n",
      "meaningful messages that can be heard with the Android app 2024 5th International Conference on Advancements in Computational Sciences (ICACS) | 979-8-3503-9478-8/24/$31.00 ©2024 IEEE | DOI: 10.1109/ICACS60934.2024.10473252\n",
      "Authorized licensed use limited to: UNIV OF ENGINEERING AND TECHNOLOGY LAHORE. Downloaded on March 22,2024 at 07:13:36 UTC from IEEE Xplore.  Restrictions apply.\n"
     ]
    }
   ],
   "source": [
    "reader = PdfReader(\"documents/Research paper.pdf\")\n",
    "pdf_texts = [p.extract_text().strip() for p in reader.pages]\n",
    "\n",
    "pdf_texts = [text for text in pdf_texts if text]\n",
    "\n",
    "print(pdf_texts[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### The reason of first doing character split and then doing SentenceTransformersTokenTextSplitter is that ```Large documents may not fit entirely into memory. By first breaking the text into character-level chunks, you can process smaller portions at a time, reducing the memory requirements for each step.```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Total chunks: 32\n"
     ]
    }
   ],
   "source": [
    "character_splitter = RecursiveCharacterTextSplitter(\n",
    "    separators=[\"\\n\\n\", \"\\n\", \". \", \" \", \"\"],\n",
    "    chunk_size=1000,\n",
    "    chunk_overlap=0\n",
    ")\n",
    "character_split_texts = character_splitter.split_text('\\n\\n'.join(pdf_texts))\n",
    "\n",
    "print(f\"\\nTotal chunks: {len(character_split_texts)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### ```Character Splitter is not enough due the reason that the embedder which we have to use has limited 256 characters or tokens context window```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Total chunks: 36\n"
     ]
    }
   ],
   "source": [
    "token_splitter = SentenceTransformersTokenTextSplitter(chunk_overlap=0, tokens_per_chunk=256) # tokens_per_chunk is context window which means that it one chunk would have 256 tokens\n",
    "\n",
    "token_split_texts = []\n",
    "for text in character_split_texts:\n",
    "    token_split_texts += token_splitter.split_text(text)\n",
    "\n",
    "print(f\"\\nTotal chunks: {len(token_split_texts)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_function = SentenceTransformerEmbeddingFunction()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "chroma_client = chromadb.Client()\n",
    "chroma_collection = chroma_client.create_collection(\"rag_app2\", embedding_function=embedding_function)\n",
    "\n",
    "ids = [str(i) for i in range(len(token_split_texts))]\n",
    "\n",
    "chroma_collection.add(ids=ids, documents=token_split_texts)\n",
    "chroma_collection.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "deafness, and speech impairments can interact with the computer with the help of 37 hand gestures using a single camera. the presented solution uses a hand tracking module from the mediapipe library for feature extraction, a random forest algorithm for the classification of gestures, and a pyautogui library for controlling the mouse and keyboard according to the classified hand gestures. the presented solution has achieved an accuracy of 99. 66 % on the test set, indicating that this system can also detect gestures for communication with deaf or speech - impaired people. overall, this system employs computer vision and machine learning techniques to improve the lives of the deaf, blind, and mute people. keywords — sign gesture, mediapipe, smart keyboard, deaf, blind, human - computer interaction i. introduction communication is an effective tool to share ideas, thoughts, and feelings. communication between humans makes life\n",
      "\n",
      "\n",
      "979 - 8 - 3503 - 9478 - 8 / 24 / $ 31. 00 ©2024 ieee machine learning and mediapipe assisted sign gesture - based smart keyboard for deaf and blind people arsalan ali department of biomedical engineering university of engineering and technology, lahore, 54890, pakistan 2019bme111 @ uet. edu. pk muhammad hamza zulfiqar department of biomedical engineering university of engineering and technology, lahore, 54890, pakistan hamzazulfiqar @ uet. edu. pkmuhammad qasim mehmood micro nano lab, electrical engineering department, information technology university ( itu ) of the punjab, ferozepur road, lahore 54600, pakistan qasim. mehmood @ itu. edu. pk abstract — there are 1. 1 billion deaf and 2. 2 billion blind people, and many people have speech impairments. these disabilities cause them to be unable to communicate with others and use modern technologies. this paper presents a real - time smart touchless keypad by which people with blindness,\n",
      "\n",
      "\n",
      "mediapipe, there is no need to train state - of - the - a rt solutions like deep convolutional neural networks computation ally. so, our solution has added a valuable addition to touch less gesture - based technologies to control the computer. this can also be used to recognize gestures, which can also help deaf and mute people. v. future work in the future, the number of signs can be increase d to enhance the vocabulary, which will broaden the spec trum of communication with technology like computers and interpersonal communication. the dynamic signs, whi ch involve movements of hands or other body parts, can be integrated for more nuanced interaction. continuous learning makes the classifier more adaptable according to us er experience. the real - time feedback mechanism can be introduced for constant learning. to increase its accessibility, the solution can be employed on different platforms like android apps, raspberry pi, etc. some specific move ment -\n",
      "\n",
      "\n",
      "vision, the second is a sensor - based solution, and the third is voice assistant - based technology that only works for blind people, not for deaf people. the first solution processes images or videos to determine the relevant sign. mobile cameras or other web - common cams can be used to take images. on the other hand, in the second solution, sensors are placed on the hand or fingers, and then the data from the sensors is analyzed to determine the relevant sign of the hand [ 5 ]. as the second solution is a sensor - based approach, also known as the data - glove approach, in which we mostly detect the hand position, angle of fingers bending, wrist movement etc. [ 6 ]. the third solution is a voice assistant - based solution which helps blind people to communicate with technology like apple siri. j. rekha used a multiclass nonlinear support vector machine to classify the signs of indian sign language with a 91. 3 % rate of recognition [ 7 ]. r. sutjiadi presented the deep\n",
      "\n",
      "\n",
      "by blind people because every blind person cannot u se voice assistant [ 19 ]. privacy of personal user data is a r ising concern regarding the voice assistant ecosystem because res earch shows that in the voice assistant ecosystem, users'personal data is stored temporarily or permanently for comme rcial or other purposes [ 20 ]. voice assistants are unable to recognize voice commands accurately in noisy environments, wh ich makes the solution ineffective [ 21 ]. we propose a real - time machine learning - based multipurpose solution in which we have devised an i ntelligent touchless keypad in which people with deafness and visual and speech impairments can interact with computers or devices. this solution can be used to recognize the signs, which can help interpersonal communication and remo ve the need for an interpreter. in this solution, we have introduced new characters which can be used for specific funct ions and\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "query = \"Which algorithm was used for Machine Learning and Mediapipe Assisted Sign Gesture-based Smart Keyboard for Deaf and Blind People?\"\n",
    "\n",
    "results = chroma_collection.query(query_texts=[query], n_results=5)\n",
    "retrieved_documents = results['documents'][0]\n",
    "\n",
    "for document in retrieved_documents:\n",
    "    print(document)\n",
    "    print('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " The algorithm used for Machine Learning and Mediapipe Assisted Sign Gesture-based Smart Keyboard for Deaf and Blind People is a Random Forest algorithm. It is used for the classification of gestures.\n"
     ]
    }
   ],
   "source": [
    "output = rag(query=query, retrieved_documents=retrieved_documents)\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "are placed in a specific 3d space, and the receiving nodes, after receiving the message from the transmitting nodes, classify the 24 signs of sign language with an accuracy of 97 % [ 13 ]. k. bhat presented a smart glove employing flex sensors to detect finger movement. the smart glove interprets the hand's signs using flex sensors and converts them into meaningful messages that can be heard with the android app 2024 5th international conference on advancements in computational sciences ( icacs ) | 979 - 8 - 3503 - 9478 - 8 / 24 / $ 31. 00 ©2024 ieee | doi : 10. 1109 / icacs60934. 2024. 10473252 authorized licensed use limited to : univ of engineering and technology lahore. downloaded on march 22, 2024 at 07 : 13 : 36 utc from ieee xplore. restrictions apply.\n",
      "\n",
      "\n",
      "want to write ‘ c ’ so, we have shown the ‘ c ’ sign to the camera, and as expected, the prediction is the lett er ‘ c ’, so the pyautigui has clicked the ‘ c ’ and we have also got alphabet ‘ c ’ in our text document. in fig. 8 ( c ), as we want to control the cursor, we have shown the mouse sign, and as ex pected, the prediction is also mouse, so pyautogui gives th e control hand via camera ; resultantly, we are controlling th e cursor with the sign. fig. 8. keypad and cursor control. ( a ) writing a with the h elp of a sign. ( b ) writing c with the help of sign. ( c ) controlling th e cursor with the use of a sign. f. comparative analysis : table ii shows that most solutions have 26 signs, w hereas our solution has 37 signs. comparative analysis shows t hat we have achieved a decent accuracy of 99. 66 %, even wit h 37 signs, distinguishing us from the present solutions. table ii. comparative analysis of different present solutions with our solution.\n",
      "\n",
      "\n",
      "vol. 12, no. 3, pp. 1541 – 1549, 2023, doi : 10. 18421 / tem123. [ 9 ] j. bora, s. dehingia, a. boruah, a. a. chetia, and d. gogoi, “ real - time assamese sign language recognition using media pipe and deep learning, ” procedia comput. sci., vol. 218, no. 202 2, pp. 1384 – 1393, 2023, doi : 10. 1016 / j. procs. 2023. 01. 117. [ 10 ] y. gu, sherrine, w. wei, x. li, j. yuan, and m. todoh, “ american sign language alphabet recognition using inertial m otion capture system with deep learning, ” inventions, vol. 7, no. 4, pp. 1 – 15, 2022, doi : 10. 3390 / inventions7040112. [ 11 ] a. m. buttar, u. ahmad, a. h. gumaei, a. assir i, and m. a. akbar, “ deep learning in sign language recognition : a hy\n",
      "\n",
      "\n",
      "165, pp. 259 – 269, 2019, doi : 10. 1016 / j. procs. 2020. 0 1. 080. [ 4 ] s. d. fisher, “ sign languages in their historic al context, ” routledge handb. hist. linguist., no. january, pp. 442 – 465, 2 014, doi : 10. 4324 / 9781315794013. ch20. [ 5 ] r. kumar, s. k. singh, a. bajpai, and a. sinha, “ mediapipe and cnns for real - time asl gesture recognition ”. [ 6 ] m. papatsimouli, p. sarigiannidis, and g. f. fr agulis, “ a survey of advancements in real - time sign language translators : integration with iot technology, ” technologies, vol. 11, no. 4, 2023, doi : 10. 3390 / technologies11040083. [ 7 ] j. rekha, j. bhattacharya, and s. majumder, “ sh ape, texture and local movement hand gesture features for indian sign lang uage recognition, ” tisc 2011\n",
      "\n",
      "\n",
      "convolution neural network that can classify the 26 signs of indonesian sign language with an accuracy of 75. 38 % [ 8 ]. jyotishman bora presented a framework that can classify only 9 static gestures of assamese sign language using feed - forward neural network with an accuracy of 99 % [ 9 ]. yutong gu presented a classification model that can classify the 26 dynamic signs of american sign language with an average accuracy of 74. 8 % [ 10 ]. a. m. buttar used a hybrid approach with mediapipe holistic model and yolov6 to classify signs with an accuracy of 92 % and 96 %, respectively [ 11 ]. francisco morillas - espejo presented a solution named sign4all based on a deep convolution neural network in which they recognized the sign using the resnet50 framework and got an accuracy of 79. 96 % on rgb images. they also designed virtual avatars to write letter by letter [ 12 ]. m. rinalduzzi presented a magnetic positioning system - based solution where the wearable transmitting nodes\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "query = \"How many sign were used in this research article ?\"\n",
    "\n",
    "results = chroma_collection.query(query_texts=[query], n_results=5)\n",
    "retrieved_documents = results['documents'][0]\n",
    "\n",
    "for document in retrieved_documents:\n",
    "    print(document)\n",
    "    print('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Based on the information provided, the answer to the question \"How many signs were used in this research article?\" is 37.\n",
      "\n",
      "The article mentions that the proposed solution uses 37 signs, which is more than the 26 signs used in most present solutions. The authors also mention that they have achieved a decent accuracy of 99.66% with 37 signs, which is comparable to the accuracy of other solutions that use fewer signs.\n",
      "\n",
      "Therefore, the answer to the question is 37, which is the number of signs used in the research article.\n"
     ]
    }
   ],
   "source": [
    "output = rag(query=query, retrieved_documents=retrieved_documents)\n",
    "print(output)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
